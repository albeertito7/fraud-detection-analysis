{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ea779e",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d120e1",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4e2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bffbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d573cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset using Kaggle API Key\n",
    "# Checking the existance of the required .csv files, if not download them\n",
    "\n",
    "ABS_PATH = \"../\"\n",
    "RAW_DATA_PATH = os.path.join( ABS_PATH, \"data/raw/\" )\n",
    "PRO_DATA_PATH = os.path.join( ABS_PATH, \"data/processed/\" )\n",
    "if not os.path.isfile( os.path.join(RAW_DATA_PATH, \"fraudTrain.csv\") ) or not os.path.isfile( os.path.join(RAW_DATA_PATH, \"fraudTest.csv\") ):\n",
    "    !python ../src/data/make_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40799c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset analysis: Train and Test reading\n",
    "df_train = pd.read_csv( os.path.join(RAW_DATA_PATH, \"fraudTrain.csv\"), index_col=0)\n",
    "df_test = pd.read_csv( os.path.join( RAW_DATA_PATH, \"fraudTest.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84338fd4",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Casting the time-related values to `Datetime`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5d4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'], errors='ignore')\n",
    "df_train['dob'] = pd.to_datetime(df_train['dob'], errors='ignore')\n",
    "\n",
    "# Test\n",
    "df_test['trans_date_trans_time'] = pd.to_datetime(df_test['trans_date_trans_time'], errors='ignore')\n",
    "df_test['dob'] = pd.to_datetime(df_test['dob'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f154e",
   "metadata": {},
   "source": [
    "Dropping irrelevant or redundant data since we already have geolocation and time data contained in other values, thus, reducing its dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04888d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['first', 'last', 'street', 'city', 'state', 'zip', 'trans_num', 'unix_time']\n",
    "\n",
    "df_train.drop(columns=drop_columns, inplace=True)\n",
    "df_test.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd4728",
   "metadata": {},
   "source": [
    "We do the calculus of the age for each card user by substracting the birthdate to the current year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556923c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['age'] = np.round((df_train['trans_date_trans_time'] - df_train['dob']) / np.timedelta64(1, 'Y'))\n",
    "df_train = df_train.astype({'age' : 'int64'})\n",
    "\n",
    "df_test['age'] = np.around((df_train['trans_date_trans_time'] - df_train['dob']) / np.timedelta64(1, 'Y'))\n",
    "df_test = df_test.astype({'age' : 'int64'})\n",
    "\n",
    "drop_columns = ['dob']\n",
    "\n",
    "df_train.drop(columns=drop_columns, inplace=True)\n",
    "df_test.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0043f4",
   "metadata": {},
   "source": [
    "Renaming a few columns for displaying purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013ca443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "trans_dict = {'trans_date_trans_time':'timestamp', 'cc_num':'credit_card_num', 'merchant':'shop', 'amt':'amount'}\n",
    "\n",
    "df_train.rename(columns=trans_dict, inplace=True)\n",
    "df_test.rename(columns=trans_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bb294",
   "metadata": {},
   "source": [
    "## Saving the results\n",
    "\n",
    "To main formats used, .csv files for a better human visualization, and the .pkl in order to load them faster into other python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(PRO_DATA_PATH, \"clean_fraudTrain.csv\"), index=False)\n",
    "df_test.to_csv(os.path.join(PRO_DATA_PATH, \"clean_fraudTest.csv\"), index=False)\n",
    "\n",
    "df_train.to_pickle(os.path.join( PRO_DATA_PATH, \"clean_fraudTrain.pkl\" ) )\n",
    "df_test.to_pickle(os.path.join( PRO_DATA_PATH, \"clean_fraudText.pkl\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
